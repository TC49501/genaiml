# -*- coding: utf-8 -*-
"""hf_rag_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/TC49501/178c5dc0ed32e3847c95fb6b8caf605c/hf_rag_test.ipynb
"""

!pip install transformers datasets faiss-cpu sentence-transformers

from transformers import AutoModelForSeq2SeqLM, AutoTokenizer

model_name = "facebook/bart-large-cnn"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

from sentence_transformers import SentenceTransformer
import faiss
import numpy as np

embedder = SentenceTransformer("sentence-transformers/all-MiniLM-L6-v2")
documents = ["Kubernetes is an open-source container orchestration platform.",
             "Docker helps package applications in lightweight containers."]

embeddings = embedder.encode(documents)
index = faiss.IndexFlatL2(embeddings.shape[1])
index.add(np.array(embeddings))

def retrieve_answer(query, index, documents):
    query_embedding = embedder.encode([query])
    distances, indices = index.search(np.array(query_embedding), k=1)
    return documents[indices[0][0]]

query = "What is Kubernetes?"
retrieved_text = retrieve_answer(query, index, documents)

inputs = tokenizer(retrieved_text, return_tensors="pt", truncation=True)
outputs = model.generate(**inputs)
final_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)

print("Answer:", final_answer)